{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa3b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78d5bba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/olgageta/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "263e8fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/olgageta/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a2435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from math import log\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0432d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4623a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Инициализация объекта MorphAnalyzer\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97166a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inverted_index(source_dir):\n",
    "    inverted_index = defaultdict(dict) \n",
    "    doc_freq = defaultdict(int) \n",
    "    total_docs = 0  \n",
    "\n",
    "    # Обход файлов в директории\n",
    "    for filename in os.listdir(source_dir):  \n",
    "        if filename.endswith(\".txt\"): \n",
    "            total_docs += 1  #счетчиком считаем количество файлов\n",
    "            file_path = os.path.join(source_dir, filename) \n",
    "            \n",
    "            # чтение файла, преобразование к нижнему регистру,создание токенов\n",
    "            with open(file_path, 'r') as file:  \n",
    "                text = file.read().lower()  \n",
    "                tokens = word_tokenize(text)  \n",
    "                term_freq = defaultdict(int) \n",
    "                \n",
    "                # для токенов- удаление пунктуации, лемматизация до базовой формы слова\n",
    "                for token in tokens: \n",
    "                    token = re.sub(r'[^\\w\\s]', '', token) \n",
    "                    lemma = morph.parse(token)[0].normal_form  \n",
    "                    term_freq[lemma] += 1  \n",
    "                    \n",
    "                # для термов и частоты их встречания в документе. увеличение частоты при встречании\n",
    "                for term, freq in term_freq.items(): \n",
    "                    inverted_index[term][filename] = freq \n",
    "                    doc_freq[term] += 1 \n",
    "                    \n",
    "\n",
    "    idf = {term: log(total_docs / freq) for term, freq in doc_freq.items()}  \n",
    "    \n",
    "    # обход термов и их частот в документах и подсчет их индекса. с обновление значения и частоты встречания\n",
    "    for term, doc_freqs in inverted_index.items(): \n",
    "        for doc, freq in doc_freqs.items():  \n",
    "            tfidf = freq * idf[term]\n",
    "            \n",
    "            \"\"\"\n",
    "            переменная inverted_index прдставляет собой словарь, где ключ - это слово или токен, \n",
    "            а значение- в каких документ и скакой частотой эти слова встречаются\n",
    "            inverted_index[term][doc] = tfidf  \n",
    "\n",
    "    return inverted_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6b21a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_inverted_index(inverted_index, words):\n",
    "    search_results = defaultdict(float)  \n",
    "    exact_match_bonus = 2.0 #увеличение веса для точного совпадения словосочетаний в документе\n",
    "\n",
    "    # обход слов, которые ищем и их лемматизация\n",
    "    for word in words:  \n",
    "        lemma = morph.parse(word)[0].normal_form \n",
    "        \n",
    "        # получение документов и их значения tfidf. увеличение счетчика при встречании. \n",
    "        for doc, tfidf in inverted_index.get(lemma, {}).items():  \n",
    "            search_results[doc] += tfidf  \n",
    "        exact_match = inverted_index.get(lemma, {}).get(lemma)  # проверка точного совпадения словосочетаний\n",
    "        \n",
    "        # увеличение значения при точной детекции словосочетания\n",
    "        if exact_match:\n",
    "            search_results[lemma] += exact_match * exact_match_bonus \n",
    "\n",
    "    return search_results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d19ec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Документы, содержащие искомые слова:\n",
      "postmodern.txt: 6.931471805599452\n"
     ]
    }
   ],
   "source": [
    "inverted_index = build_inverted_index(source_dir)  \n",
    "\n",
    "search_words = [\"симпсон\", \"устарел\"] \n",
    "results = search_inverted_index(inverted_index, search_words) \n",
    "\n",
    "\"\"\"\n",
    "сортировка результатов по убыванию, чтобы найти документ с наиболее точным совпадением\n",
    "вывожу score который считается в функции search_inverted_index, он \n",
    "подсчитывается путем суммирования tfidf значений для всех слов из запроса поиска\n",
    "\"\"\"\n",
    "\n",
    "if results:\n",
    "    sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)  \n",
    "    print(\"Документы с искомыми словами:\")\n",
    "    for doc, score in sorted_results:\n",
    "        print(f\"{doc}: {score}\")\n",
    "else:\n",
    "    print(\"Нет документов с такими словами\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c39f9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Документы с искомыми словами:\n",
      "allmodern.txt: 4.720696194884877\n",
      "metamodern.txt: 3.4000688682823563\n",
      "postmodern.txt: 0.28768207245178085\n"
     ]
    }
   ],
   "source": [
    "inverted_index = build_inverted_index(source_dir)  \n",
    "\n",
    "search_words = [\"смена\", \"постмодерна\"] \n",
    "results = search_inverted_index(inverted_index, search_words) \n",
    "\n",
    "\"\"\"\n",
    "сортировка результатов по убыванию, чтобы найти документ с наиболее точным совпадением\n",
    "вывожу score который считается в функции search_inverted_index, он \n",
    "подсчитывается путем суммирования tfidf значений для всех слов из запроса поиска\n",
    "\"\"\"\n",
    "\n",
    "if results:\n",
    "    sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)  \n",
    "    print(\"Документы с искомыми словами:\")\n",
    "    for doc, score in sorted_results:\n",
    "        print(f\"{doc}: {score}\")\n",
    "else:\n",
    "    print(\"Нет документов с такими словами\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b0a7707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Документы с искомыми словами:\n",
      "modernart.txt: 5.753641449035617\n",
      "metamodern.txt: 0.8630462173553426\n",
      "allmodern.txt: 0.28768207245178085\n",
      "postmodern.txt: 0.0\n"
     ]
    }
   ],
   "source": [
    "inverted_index = build_inverted_index(source_dir)  \n",
    "\n",
    "search_words = [\"современное\", \"искусство\"] \n",
    "results = search_inverted_index(inverted_index, search_words) \n",
    "\n",
    "\"\"\"\n",
    "сортировка результатов по убыванию, чтобы найти документ с наиболее точным совпадением\n",
    "вывожу score который считается в функции search_inverted_index, он \n",
    "подсчитывается путем суммирования tfidf значений для всех слов из запроса поиска\n",
    "\"\"\"\n",
    "\n",
    "if results:\n",
    "    sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)  \n",
    "    print(\"Документы с искомыми словами:\")\n",
    "    for doc, score in sorted_results:\n",
    "        print(f\"{doc}: {score}\")\n",
    "else:\n",
    "    print(\"Нет документов с такими словами\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f472c7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Документы с искомыми словами:\n",
      "metamodern.txt: 1.6739764335716714\n",
      "allmodern.txt: 0.28768207245178085\n",
      "postmodern.txt: 0.28768207245178085\n"
     ]
    }
   ],
   "source": [
    "inverted_index = build_inverted_index(source_dir)  \n",
    "\n",
    "search_words = [\"традиционализм\", \"современность\"] \n",
    "results = search_inverted_index(inverted_index, search_words) \n",
    "\n",
    "\"\"\"\n",
    "сортировка результатов по убыванию, чтобы найти документ с наиболее точным совпадением\n",
    "вывожу score который считается в функции search_inverted_index, он \n",
    "подсчитывается путем суммирования tfidf значений для всех слов из запроса поиска\n",
    "\"\"\"\n",
    "\n",
    "if results:\n",
    "    sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)  \n",
    "    print(\"Документы с искомыми словами:\")\n",
    "    for doc, score in sorted_results:\n",
    "        print(f\"{doc}: {score}\")\n",
    "else:\n",
    "    print(\"Нет документов с такими словами\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960a22fc",
   "metadata": {},
   "source": [
    "Проверяю функцию, которая приводит искомые слова в исходные формы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b214a4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Документы с искомыми словами:\n",
      "allmodern.txt: 9.010913347279288\n",
      "modernart.txt: 1.3862943611198906\n",
      "postmodern.txt: 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "inverted_index = build_inverted_index(source_dir)  \n",
    "\n",
    "search_words = [\"рефлексируя\", \"над\", \"уже\", \"созданным\"] \n",
    "results = search_inverted_index(inverted_index, search_words) \n",
    "\n",
    "\"\"\"\n",
    "сортировка результатов по убыванию, чтобы найти документ с наиболее точным совпадением\n",
    "вывожу score который считается в функции search_inverted_index, он \n",
    "подсчитывается путем суммирования tfidf значений для всех слов из запроса поиска\n",
    "\"\"\"\n",
    "\n",
    "if results:\n",
    "    sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)  \n",
    "    print(\"Документы с искомыми словами:\")\n",
    "    for doc, score in sorted_results:\n",
    "        print(f\"{doc}: {score}\")\n",
    "else:\n",
    "    print(\"Нет документов с такими словами\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f12ebf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Документы с искомыми словами:\n",
      "allmodern.txt: 9.010913347279288\n",
      "modernart.txt: 1.3862943611198906\n",
      "postmodern.txt: 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "inverted_index = build_inverted_index(source_dir)  \n",
    "\n",
    "search_words = [\"рефлексировать\", \"над\", \"уже\", \"создать\"] \n",
    "results = search_inverted_index(inverted_index, search_words) \n",
    "\n",
    "\"\"\"\n",
    "сортировка результатов по убыванию, чтобы найти документ с наиболее точным совпадением\n",
    "вывожу score который считается в функции search_inverted_index, он \n",
    "подсчитывается путем суммирования tfidf значений для всех слов из запроса поиска\n",
    "\"\"\"\n",
    "\n",
    "if results:\n",
    "    sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)  \n",
    "    print(\"Документы с искомыми словами:\")\n",
    "    for doc, score in sorted_results:\n",
    "        print(f\"{doc}: {score}\")\n",
    "else:\n",
    "    print(\"Нет документов с такими словами\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c77cb57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
